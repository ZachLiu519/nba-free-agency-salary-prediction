{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from requests.adapters import HTTPAdapter\n",
    "from requests.packages.urllib3.util.retry import Retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "import time\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define elements for scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_headers = {'Proxy-Connection': 'keep-alive',\n",
    "    'Cache-Control': 'max-age=0',\n",
    "    'Upgrade-Insecure-Requests': '1',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.55 Safari/537.36 Edg/96.0.1054.43',\n",
    "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'Accept-Language': 'en,zh-CN;q=0.9,zh;q=0.8,en-US;q=0.7'}\n",
    "seasons = [season for season in range(2005, 2022)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_player_salaries(season):\n",
    "    session = requests.Session()\n",
    "    retry = Retry(connect=3, backoff_factor=0.5)\n",
    "    adapter = HTTPAdapter(max_retries=retry)\n",
    "    session.mount('http://', adapter)\n",
    "    session.mount('https://', adapter)\n",
    "    \n",
    "    url = 'http://www.espn.com/nba/salaries/_/year/{0}'.format(season+1)\n",
    "    \n",
    "    response = session.get(url, headers=my_headers)\n",
    "    response_status = re.search(r'\\d+', str(response))[0]\n",
    "    if response_status != '200': # handle fail case from response\n",
    "        print(response_status)\n",
    "        return None\n",
    "\n",
    "    # parse\n",
    "    html_soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    page_numbers = int(html_soup.find('div', {'class': 'page-numbers'}).text[-2:])\n",
    "    \n",
    "    table = pd.DataFrame()\n",
    "    for page in range(1, page_numbers+1):\n",
    "        url_page = 'http://www.espn.com/nba/salaries/_/year/{0}/page/{1}'.format(season+1, page)\n",
    "        response_page = session.get(url_page, headers=my_headers)\n",
    "        response_status = re.search(r'\\d+', str(response_page))[0]\n",
    "        if response_status != '200': # handle fail case from response\n",
    "            print(response_status)\n",
    "            print(url)\n",
    "            continue\n",
    "        \n",
    "        soup_page = BeautifulSoup(response_page.text, 'html.parser')\n",
    "        table = pd.concat([table, pd.read_html(str(soup_page.find_all('table')[0]))[0]])\n",
    "    \n",
    "    table = table.loc[table[0].apply(lambda x: x != 'RK')]\n",
    "    table[3] = table[3].apply(lambda x: int(re.sub(r'[^\\d.]', '', x)))\n",
    "    table['season'] = str(season) + \"-\" + str(season+1)[2:]\n",
    "    table.rename({1: 'Player', 3: 'Salary'}, inplace=True, axis=1)\n",
    "    \n",
    "    return table[['Player', 'Salary', 'season']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(12) as p:\n",
    "    player_salary = p.map(all_player_salaries, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_salaries = pd.DataFrame()\n",
    "for t in player_salary:\n",
    "    player_salaries = pd.concat([player_salaries, t])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_encoding(string):\n",
    "    return unicodedata.normalize('NFKD', string).encode(\"ascii\",\"ignore\").decode()\n",
    "def fix_dot(string):\n",
    "    if string.count('.') > 1:\n",
    "        clean = \"\".join(re.findall(r'[\\w]+', string))\n",
    "        return clean[:2] + \" \" + clean[2:]\n",
    "    else:\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "player_salaries['Player'] = player_salaries['Player'].apply(lambda x: re.sub(r',.+', '', x)).apply(fix_encoding).apply(fix_dot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('player_salaries.pickle', 'wb') as handle:\n",
    "    pickle.dump(player_salaries, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('DataScience': conda)",
   "language": "python",
   "name": "python38264bitdatascienceconda6647aa692cd647ca976aaa01095ed2f6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
